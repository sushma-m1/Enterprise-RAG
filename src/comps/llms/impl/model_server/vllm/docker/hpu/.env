# Copyright (C) 2024-2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

## Provide your Hugging Face API key to enable access to Hugging Face models.
#HF_TOKEN=<your-hf-api-key>

## VLLM Model Server Settings ##
LLM_VLLM_MODEL_NAME="Intel/neural-chat-7b-v3-3"
LLM_VLLM_PORT=8008

#LLM_CONNECTOR="langchain" # Defaults to "generic" if not set. Options: "langchain", "generic".

## FP8 Quantization settings
# FP8_DATASET_PATH=<path to calibration dataset in pkl format>

## HABANA Settings ##
HABANA_VISIBLE_DEVICES=all # "1,4,7,0"
OMPI_MCA_btl_vader_single_copy_mechanism=none
PT_HPU_ENABLE_LAZY_COLLECTIVES=true
PT_HPU_LAZY_ACC_PAR_MODE=0
PT_HPU_LAZY_MODE=1

## VLLM Settings ##
VLLM_CPU_KVCACHE_SPACE=40
VLLM_DTYPE=bfloat16
VLLM_MAX_NUM_SEQS=512
VLLM_BLOCK_SIZE=128
VLLM_SKIP_WARMUP=true
VLLM_TP_SIZE=8
VLLM_ENABLE_EXPERT_PARALLEL=0

## Proxy Settings â€“ Uncomment if Needed ##
#NO_PROXY=<your-no-proxy>
#HTTP_PROXY=<your-http-proxy>
#HTTPS_PROXY=<your-https-proxy>

