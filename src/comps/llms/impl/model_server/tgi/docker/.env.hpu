# Copyright (C) 2024-2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

## Provide your Hugging Face API key to enable access to Hugging Face models.
# HF_TOKEN=<your-hf-api-key>

## TGI Model Server Settings
LLM_TGI_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.1
LLM_TGI_PORT=8008

#LLM_CONNECTOR="langchain" # Defaults to "generic" if not set. Options: "langchain", "generic".

# Since we support MAX_NEW_TOKENS=4096, the value of MAX_TOTAL_TOKENS should be at least MAX_NEW_TOKENS+MAX_INPUT_TOKENS
MAX_INPUT_TOKENS=1024
MAX_TOTAL_TOKENS=5120
PAD_SEQUENCE_TO_MULTIPLE_OF=256

# FP8 Specific Settings
# IF_FP8_QUANTIZATION=false
# FP8_QUANTIZE_MODEL_PATH=

## HABANA Settings
HABANA_VISIBLE_DEVICES=all # "1,4,7,0"
SHARDED=true # true, false
NUM_SHARD=8  # expected to be greater than 1 if SHARDED is true; otherwise, set to 1.
OMPI_MCA_btl_vader_single_copy_mechanism=none
PT_HPU_ENABLE_LAZY_COLLECTIVES=true

## Proxy Settings â€“ Uncomment if Needed ##
# NO_PROXY=<your-no-proxy>
# HTTP_PROXY=<your-http-proxy>
# HTTPS_PROXY=<your-https-proxy>
